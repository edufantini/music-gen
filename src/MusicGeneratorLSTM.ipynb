{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGeneratorLSTM.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO0Xjbi/90F/S0erZnbEs9d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edufantini/music-gen/blob/main/src/MusicGeneratorLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wkARadSlGB2"
      },
      "source": [
        "# Music Generator with LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5hn1sHZlMEK"
      },
      "source": [
        "##About"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmmZd52Ullwl"
      },
      "source": [
        "Music resamples language as a temporal sequence of articulated sounds. They say something, often something human.\n",
        "\n",
        "Although, there are crucial differences between language and music. We can still describe it as a sequence of symbols in the simplest form of understanding. Translating something complex into something simpler, but usable by computational models.\n",
        "\n",
        "Thus, the objective of this project is to establish a communication between the human, that understands music in the most intense way that the brain can interpret through information, and the machine.\n",
        "\n",
        "We'll create a model that can generate music based on the input information, i.e., generate a sequence of sounds which are related in some way with the sounds passed as input.\n",
        "\n",
        "We'll use Natural Language Processing (NLP) methods, observing the music as it were a language, abstracting it. Doing this, the machine can recognize and process similar data.\n",
        "\n",
        "On the first step, we'll use text generation techniques, using Recurrent Neural Networks (RNNs) and Long-Short Term Memories (LSTMs). With the effectiveness of the training, even if it's reasonable, we'll perform the same implementation using specific methods such as Attention.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi_qPalLptT_"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKgKH6V3pU6J"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WelzCmd7pzlv"
      },
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl1QEJREpepK"
      },
      "source": [
        "## Creating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irw70iZkp9BY"
      },
      "source": [
        "## Compile and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK-gjMK8qLp-"
      },
      "source": [
        "## Generate text"
      ]
    }
  ]
}